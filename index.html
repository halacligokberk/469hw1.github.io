<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>My Blog</title>
  <style>
    /* Base styling */
    body {
      font-family: Arial, sans-serif;
      background-color: #f4f4f4;
      margin: 0;
      padding: 0;
      line-height: 1.6;
    }
    /* Header styling */
    header {
      background-color: #333;
      color: #fff;
      padding: 1rem 0;
      text-align: center;
    }
    header nav ul {
      list-style: none;
      padding: 0;
      margin: 0;
    }
    header nav ul li {
      display: inline;
      margin: 0 10px;
    }
    header nav ul li a {
      color: #fff;
      text-decoration: none;
    }
    /* Container for content */
    .container {
      width: 90%;
      max-width: 800px;
      margin: 20px auto;
      padding: 0 10px;
    }
    /* Article styling */
    article {
      background-color: #fff;
      padding: 20px;
      margin-bottom: 20px;
      border-radius: 5px;
      box-shadow: 0 2px 5px rgba(0,0,0,0.1);
    }
    /* Footer styling */
    footer {
      background-color: #333;
      color: #fff;
      text-align: center;
      padding: 1rem 0;
      position: fixed;
      width: 100%;
      bottom: 0;
    }
  </style>
</head>
<body>
  <header>
    <h1>Gökberk's Graphics Blog</h1>
    <nav>
      <ul>
        <li><a href="#home">Home</a></li>
        <li><a href="#about">About</a></li>
      </ul>
    </nav>
  </header>
  
  <div class="container">
    <!-- Blog Post Sample -->
    <article>
      <h2>CENG 469 HW1 Blog</h2>
      <p> 
        
        <h3>Bezier Surface Rendering</h3>
        
        I started this homework by rendering a simple bezier curve mesh. We already have a sample program which can parse and render <code>.obj</code> files in OpenGL
        To make use of the already existing rendering pipeline. I decided to create and define my Bezier surfaces in a similar way. The <code>.obj</code> parser fills a 
        <code>vector</code> container for normals, faces and vertices etc. I wrote a function <code>add_surface</code> which tesellates the bezier surfaces and fills the aforementioned vectors
        in the same way as the <code>.obj</code> parser to have compatibility with the rest of the rendering pipeline. Setting up the mesh wasn't so hard. I did some mistakes while 
        calculating the normals. One of the mistakes was having the wrong order for calculating normals. The other was calculating the faces one by one, this lead to repetition of 
        some vertices. Because of that, I had a shadowy-looking mesh. To solve that problem I changed the tessellation algorithm. My tesellation algorithm is as follows:

        <ul>
        <li>
          1. Calculate vertices and put them in a vector and create an empty vector for <code>temp_normals</code>.
        </li>

        <li>
        2. Iterate over vertices and define faces, during that iteration calculate normals for each face and add the normal of each face to the corresponding elements of the 
        <code>temp_normals</code> vector.
        </li>

        <li>
        3. Finally normalize the normals based on the number of neighbouring faces it has.
        </li>
        </ul>

        <h3>Bezier Curve Rendering</h3>

          We also need to render Bezier curves to the screen. I did this by sampling points from a Bezier Curve which I implemented using Bernstein polynomials in the <code>sample_bezier_curve</code> function
          under the <code>utils.h</code> library. Then I rendered the curve using a simple line renderer. Until here it was straightforward. Then I come across a problem: We need to generate Bezier curves on the 
          fly and they should always stay visible to the user. Generating random control points and ensuring C0 and C1 continuity was easy but I really didn't know how can i keep the curve in the frustrum. Checking if an world coordinate appears 
          in the screen is hard and generating such a point requires a brute force method. I did some research on this problem and found out that I can solve this problem in reverse order. Firstly revisit the transformations 
          we make on the way:

          <br>
          <br>
          
          Object Coordinates --Modelling Transformation--> World Coordinates --Camera Transformation--> Camera Coordinates --Projection Transformation--> Clip Coordinates --Perspective Divide--> NDC

          <br>
          <br>

          It is given that any point in the NDC space appears in the screen. Since it is bounded between -1 and 1 for every axis, I can sample visible points by generating points from NDC space and inverse transforming them into
          the world coordinates. It seems like very hard work but its very simple. All we need to do is multiply projection matrix and camera matrix and take the inverse of the resulting matrix. This inverse matrix can map any point
          from NDC space to the world coordinates. With this method, I devised a way to generate visible Bezier curves in real time.


      </p>
    </article>
    
    <!-- Additional blog posts can go here -->
    
  </div>
  
  <footer>
    <p>&copy; 2025, Eren Gökberk Halaçlı</p>
  </footer>
</body>
</html>

